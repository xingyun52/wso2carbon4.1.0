PREHOOK: query: create table nzhang_Tmp(a int, b string)
PREHOOK: type: CREATETABLE
POSTHOOK: query: create table nzhang_Tmp(a int, b string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@nzhang_Tmp
PREHOOK: query: select * from nzhang_Tmp
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_tmp
PREHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-14_493_1342587779151203373/-mr-10000
POSTHOOK: query: select * from nzhang_Tmp
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_tmp
POSTHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-14_493_1342587779151203373/-mr-10000
PREHOOK: query: explain create table nzhang_CTAS1 as select key k, value from src sort by k, value limit 10
PREHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: query: explain create table nzhang_CTAS1 as select key k, value from src sort by k, value limit 10
POSTHOOK: type: CREATETABLE_AS_SELECT
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE (TOK_TABNAME nzhang_CTAS1) TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key) k) (TOK_SELEXPR (TOK_TABLE_OR_COL value))) (TOK_SORTBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL k)) (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value))) (TOK_LIMIT 10))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-4 depends on stages: Stage-0
  Stage-3 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            Select Operator
              expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
              outputColumnNames: _col0, _col1
              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
                sort order: ++
                tag: -1
                value expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/tmp/rsurowka/hive_2011-11-07_19-53-14_740_6068039279320291425/-mr-10002 
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
              sort order: ++
              tag: -1
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 1
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  name: default.nzhang_CTAS1

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
          destination: pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/nzhang_ctas1

  Stage: Stage-4
      Create Table Operator:
        Create Table
          columns: k string, value string
          if not exists: false
          input format: org.apache.hadoop.mapred.TextInputFormat
          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          name: nzhang_CTAS1
          isExternal: false

  Stage: Stage-3
    Stats-Aggr Operator


PREHOOK: query: create table nzhang_CTAS1 as select key k, value from src sort by k, value limit 10
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
POSTHOOK: query: create table nzhang_CTAS1 as select key k, value from src sort by k, value limit 10
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: default@nzhang_CTAS1
PREHOOK: query: select * from nzhang_CTAS1
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_ctas1
PREHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-24_168_1052652908826092056/-mr-10000
POSTHOOK: query: select * from nzhang_CTAS1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_ctas1
POSTHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-24_168_1052652908826092056/-mr-10000
0	val_0
0	val_0
0	val_0
10	val_10
100	val_100
100	val_100
103	val_103
103	val_103
104	val_104
104	val_104
PREHOOK: query: describe formatted nzhang_CTAS1
PREHOOK: type: DESCTABLE
POSTHOOK: query: describe formatted nzhang_CTAS1
POSTHOOK: type: DESCTABLE
# col_name            	data_type           	comment             
	 	 
k                   	string              	None                
value               	string              	None                
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
Owner:              	rsurowka            	 
CreateTime:         	Mon Nov 07 19:53:23 PST 2011	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/nzhang_ctas1	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	numFiles            	1                   
	numPartitions       	0                   
	numRows             	10                  
	rawDataSize         	96                  
	totalSize           	106                 
	transient_lastDdlTime	1320724404          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: explain create table nzhang_ctas2 as select * from src sort by key, value limit 10
PREHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: query: explain create table nzhang_ctas2 as select * from src sort by key, value limit 10
POSTHOOK: type: CREATETABLE_AS_SELECT
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE (TOK_TABNAME nzhang_ctas2) TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_SORTBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL key)) (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value))) (TOK_LIMIT 10))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-4 depends on stages: Stage-0
  Stage-3 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            Select Operator
              expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
              outputColumnNames: _col0, _col1
              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
                sort order: ++
                tag: -1
                value expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/tmp/rsurowka/hive_2011-11-07_19-53-24_458_6741209951969271935/-mr-10002 
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
              sort order: ++
              tag: -1
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 1
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  name: default.nzhang_ctas2

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
          destination: pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/nzhang_ctas2

  Stage: Stage-4
      Create Table Operator:
        Create Table
          columns: key string, value string
          if not exists: false
          input format: org.apache.hadoop.mapred.TextInputFormat
          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          name: nzhang_ctas2
          isExternal: false

  Stage: Stage-3
    Stats-Aggr Operator


PREHOOK: query: create table nzhang_ctas2 as select * from src sort by key, value limit 10
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
POSTHOOK: query: create table nzhang_ctas2 as select * from src sort by key, value limit 10
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: default@nzhang_ctas2
PREHOOK: query: select * from nzhang_ctas2
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_ctas2
PREHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-31_886_3453511835007488493/-mr-10000
POSTHOOK: query: select * from nzhang_ctas2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_ctas2
POSTHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-31_886_3453511835007488493/-mr-10000
0	val_0
0	val_0
0	val_0
10	val_10
100	val_100
100	val_100
103	val_103
103	val_103
104	val_104
104	val_104
PREHOOK: query: describe formatted nzhang_CTAS2
PREHOOK: type: DESCTABLE
POSTHOOK: query: describe formatted nzhang_CTAS2
POSTHOOK: type: DESCTABLE
# col_name            	data_type           	comment             
	 	 
key                 	string              	None                
value               	string              	None                
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
Owner:              	rsurowka            	 
CreateTime:         	Mon Nov 07 19:53:31 PST 2011	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/nzhang_ctas2	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	numFiles            	1                   
	numPartitions       	0                   
	numRows             	10                  
	rawDataSize         	96                  
	totalSize           	106                 
	transient_lastDdlTime	1320724411          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: explain create table nzhang_ctas3 row format serde "org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe" stored as RCFile as select key/2 half_key, concat(value, "_con") conb  from src sort by half_key, conb limit 10
PREHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: query: explain create table nzhang_ctas3 row format serde "org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe" stored as RCFile as select key/2 half_key, concat(value, "_con") conb  from src sort by half_key, conb limit 10
POSTHOOK: type: CREATETABLE_AS_SELECT
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE (TOK_TABNAME nzhang_ctas3) TOK_LIKETABLE (TOK_TABLESERIALIZER (TOK_SERDENAME "org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe")) TOK_TBLRCFILE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (/ (TOK_TABLE_OR_COL key) 2) half_key) (TOK_SELEXPR (TOK_FUNCTION concat (TOK_TABLE_OR_COL value) "_con") conb)) (TOK_SORTBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL half_key)) (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL conb))) (TOK_LIMIT 10))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-4 depends on stages: Stage-0
  Stage-3 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            Select Operator
              expressions:
                    expr: (key / 2)
                    type: double
                    expr: concat(value, '_con')
                    type: string
              outputColumnNames: _col0, _col1
              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: double
                      expr: _col1
                      type: string
                sort order: ++
                tag: -1
                value expressions:
                      expr: _col0
                      type: double
                      expr: _col1
                      type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/tmp/rsurowka/hive_2011-11-07_19-53-32_176_3137057323851157959/-mr-10002 
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: double
                    expr: _col1
                    type: string
              sort order: ++
              tag: -1
              value expressions:
                    expr: _col0
                    type: double
                    expr: _col1
                    type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 1
              table:
                  input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
                  name: default.nzhang_ctas3

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
          destination: pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/nzhang_ctas3

  Stage: Stage-4
      Create Table Operator:
        Create Table
          columns: half_key double, conb string
          if not exists: false
          input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
          serde name: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
          name: nzhang_ctas3
          isExternal: false

  Stage: Stage-3
    Stats-Aggr Operator


PREHOOK: query: create table nzhang_ctas3 row format serde "org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe" stored as RCFile as select key/2 half_key, concat(value, "_con") conb  from src sort by half_key, conb limit 10
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
POSTHOOK: query: create table nzhang_ctas3 row format serde "org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe" stored as RCFile as select key/2 half_key, concat(value, "_con") conb  from src sort by half_key, conb limit 10
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: default@nzhang_ctas3
PREHOOK: query: select * from nzhang_ctas3
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_ctas3
PREHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-39_570_5842680857812811926/-mr-10000
POSTHOOK: query: select * from nzhang_ctas3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_ctas3
POSTHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-39_570_5842680857812811926/-mr-10000
0.0	val_0_con
0.0	val_0_con
0.0	val_0_con
1.0	val_2_con
2.0	val_4_con
2.5	val_5_con
2.5	val_5_con
2.5	val_5_con
4.0	val_8_con
4.5	val_9_con
PREHOOK: query: describe formatted nzhang_CTAS3
PREHOOK: type: DESCTABLE
POSTHOOK: query: describe formatted nzhang_CTAS3
POSTHOOK: type: DESCTABLE
# col_name            	data_type           	comment             
	 	 
half_key            	double              	None                
conb                	string              	None                
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
Owner:              	rsurowka            	 
CreateTime:         	Mon Nov 07 19:53:39 PST 2011	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/nzhang_ctas3	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	numFiles            	1                   
	numPartitions       	0                   
	numRows             	10                  
	rawDataSize         	120                 
	totalSize           	294                 
	transient_lastDdlTime	1320724419          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe	 
InputFormat:        	org.apache.hadoop.hive.ql.io.RCFileInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.RCFileOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: explain create table if not exists nzhang_ctas3 as select key, value from src sort by key, value limit 2
PREHOOK: type: CREATETABLE
POSTHOOK: query: explain create table if not exists nzhang_ctas3 as select key, value from src sort by key, value limit 2
POSTHOOK: type: CREATETABLE
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE (TOK_TABNAME nzhang_ctas3) TOK_IFNOTEXISTS TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value))) (TOK_SORTBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL key)) (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value))) (TOK_LIMIT 2))))

STAGE DEPENDENCIES:

STAGE PLANS:
STAGE PLANS:
PREHOOK: query: create table if not exists nzhang_ctas3 as select key, value from src sort by key, value limit 2
PREHOOK: type: CREATETABLE
POSTHOOK: query: create table if not exists nzhang_ctas3 as select key, value from src sort by key, value limit 2
POSTHOOK: type: CREATETABLE
PREHOOK: query: select * from nzhang_ctas3
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_ctas3
PREHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-39_957_8795808764737341610/-mr-10000
POSTHOOK: query: select * from nzhang_ctas3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_ctas3
POSTHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-39_957_8795808764737341610/-mr-10000
0.0	val_0_con
0.0	val_0_con
0.0	val_0_con
1.0	val_2_con
2.0	val_4_con
2.5	val_5_con
2.5	val_5_con
2.5	val_5_con
4.0	val_8_con
4.5	val_9_con
PREHOOK: query: describe formatted nzhang_CTAS3
PREHOOK: type: DESCTABLE
POSTHOOK: query: describe formatted nzhang_CTAS3
POSTHOOK: type: DESCTABLE
# col_name            	data_type           	comment             
	 	 
half_key            	double              	None                
conb                	string              	None                
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
Owner:              	rsurowka            	 
CreateTime:         	Mon Nov 07 19:53:39 PST 2011	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/nzhang_ctas3	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	numFiles            	1                   
	numPartitions       	0                   
	numRows             	10                  
	rawDataSize         	120                 
	totalSize           	294                 
	transient_lastDdlTime	1320724419          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe	 
InputFormat:        	org.apache.hadoop.hive.ql.io.RCFileInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.RCFileOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: explain create table nzhang_ctas4 row format delimited fields terminated by ',' stored as textfile as select key, value from src sort by key, value limit 10
PREHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: query: explain create table nzhang_ctas4 row format delimited fields terminated by ',' stored as textfile as select key, value from src sort by key, value limit 10
POSTHOOK: type: CREATETABLE_AS_SELECT
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE (TOK_TABNAME nzhang_ctas4) TOK_LIKETABLE (TOK_TABLEROWFORMAT (TOK_SERDEPROPS (TOK_TABLEROWFORMATFIELD ','))) TOK_TBLTEXTFILE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value))) (TOK_SORTBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL key)) (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value))) (TOK_LIMIT 10))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-4 depends on stages: Stage-0
  Stage-3 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            Select Operator
              expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
              outputColumnNames: _col0, _col1
              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
                sort order: ++
                tag: -1
                value expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/tmp/rsurowka/hive_2011-11-07_19-53-40_251_2495661714018508871/-mr-10002 
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
              sort order: ++
              tag: -1
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 1
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  name: default.nzhang_ctas4

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
          destination: pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/nzhang_ctas4

  Stage: Stage-4
      Create Table Operator:
        Create Table
          columns: key string, value string
          field delimiter: ,
          if not exists: false
          input format: org.apache.hadoop.mapred.TextInputFormat
          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          name: nzhang_ctas4
          isExternal: false

  Stage: Stage-3
    Stats-Aggr Operator


PREHOOK: query: create table nzhang_ctas4 row format delimited fields terminated by ',' stored as textfile as select key, value from src sort by key, value limit 10
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
POSTHOOK: query: create table nzhang_ctas4 row format delimited fields terminated by ',' stored as textfile as select key, value from src sort by key, value limit 10
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: default@nzhang_ctas4
PREHOOK: query: select * from nzhang_ctas4
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_ctas4
PREHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-47_574_4018493574829459966/-mr-10000
POSTHOOK: query: select * from nzhang_ctas4
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_ctas4
POSTHOOK: Output: file:/tmp/rsurowka/hive_2011-11-07_19-53-47_574_4018493574829459966/-mr-10000
0	val_0
0	val_0
0	val_0
10	val_10
100	val_100
100	val_100
103	val_103
103	val_103
104	val_104
104	val_104
PREHOOK: query: describe formatted nzhang_CTAS4
PREHOOK: type: DESCTABLE
POSTHOOK: query: describe formatted nzhang_CTAS4
POSTHOOK: type: DESCTABLE
# col_name            	data_type           	comment             
	 	 
key                 	string              	None                
value               	string              	None                
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
Owner:              	rsurowka            	 
CreateTime:         	Mon Nov 07 19:53:47 PST 2011	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/nzhang_ctas4	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	numFiles            	1                   
	numPartitions       	0                   
	numRows             	10                  
	rawDataSize         	96                  
	totalSize           	106                 
	transient_lastDdlTime	1320724427          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	field.delim         	,                   
	serialization.format	,                   
PREHOOK: query: explain extended create table nzhang_ctas5 row format delimited fields terminated by ',' lines terminated by '\012' stored as textfile as select key, value from src sort by key, value limit 10
PREHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: query: explain extended create table nzhang_ctas5 row format delimited fields terminated by ',' lines terminated by '\012' stored as textfile as select key, value from src sort by key, value limit 10
POSTHOOK: type: CREATETABLE_AS_SELECT
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE (TOK_TABNAME nzhang_ctas5) TOK_LIKETABLE (TOK_TABLEROWFORMAT (TOK_SERDEPROPS (TOK_TABLEROWFORMATFIELD ',') (TOK_TABLEROWFORMATLINES '\012'))) TOK_TBLTEXTFILE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value))) (TOK_SORTBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL key)) (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value))) (TOK_LIMIT 10))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-4 depends on stages: Stage-0
  Stage-3 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            GatherStats: false
            Select Operator
              expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
              outputColumnNames: _col0, _col1
              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
                sort order: ++
                tag: -1
                value expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
      Needs Tagging: false
      Path -> Alias:
        pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/src [src]
      Path -> Partition:
        pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/src 
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value
              columns.types string:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/src
              name default.src
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              transient_lastDdlTime 1320724392
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.types string:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/src
                name default.src
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1320724392
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 0
              directory: file:/tmp/rsurowka/hive_2011-11-07_19-53-47_870_2575560272213439831/-mr-10002
              NumFilesPerFileSink: 1
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string,string
                    escape.delim \
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/tmp/rsurowka/hive_2011-11-07_19-53-47_870_2575560272213439831/-mr-10002 
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
              sort order: ++
              tag: -1
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
      Needs Tagging: false
      Path -> Alias:
        file:/tmp/rsurowka/hive_2011-11-07_19-53-47_870_2575560272213439831/-mr-10002 [file:/tmp/rsurowka/hive_2011-11-07_19-53-47_870_2575560272213439831/-mr-10002]
      Path -> Partition:
        file:/tmp/rsurowka/hive_2011-11-07_19-53-47_870_2575560272213439831/-mr-10002 
          Partition
            base file name: -mr-10002
            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
            properties:
              columns _col0,_col1
              columns.types string,string
              escape.delim \
          
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              properties:
                columns _col0,_col1
                columns.types string,string
                escape.delim \
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 1
              directory: pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/scratchdir/hive_2011-11-07_19-53-47_870_2575560272213439831/-ext-10001
              NumFilesPerFileSink: 1
              Stats Publishing Key Prefix: pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/scratchdir/hive_2011-11-07_19-53-47_870_2575560272213439831/-ext-10001/
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string:string
                    field.delim ,
                    line.delim 

                    name default.nzhang_ctas5
                    serialization.format ,
                  name: default.nzhang_ctas5
              TotalFiles: 1
              GatherStats: true
              MultiFileSpray: false

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
          source: pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/scratchdir/hive_2011-11-07_19-53-47_870_2575560272213439831/-ext-10001
          destination: pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/test/data/warehouse/nzhang_ctas5

  Stage: Stage-4
      Create Table Operator:
        Create Table
          columns: key string, value string
          field delimiter: ,
          if not exists: false
          input format: org.apache.hadoop.mapred.TextInputFormat
          line delimiter: 

          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          name: nzhang_ctas5
          isExternal: false

  Stage: Stage-3
    Stats-Aggr Operator
      Stats Aggregation Key Prefix: pfile:/data/users/rsurowka/JAVA_HIVE/apache-hive/build/ql/scratchdir/hive_2011-11-07_19-53-47_870_2575560272213439831/-ext-10001/


PREHOOK: query: create table nzhang_ctas5 row format delimited fields terminated by ',' lines terminated by '\012' stored as textfile as select key, value from src sort by key, value limit 10
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
POSTHOOK: query: create table nzhang_ctas5 row format delimited fields terminated by ',' lines terminated by '\012' stored as textfile as select key, value from src sort by key, value limit 10
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: default@nzhang_ctas5
PREHOOK: query: create table nzhang_ctas6 (key string, `to` string)
PREHOOK: type: CREATETABLE
POSTHOOK: query: create table nzhang_ctas6 (key string, `to` string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@nzhang_ctas6
PREHOOK: query: insert overwrite table nzhang_ctas6 select key, value from src limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@nzhang_ctas6
POSTHOOK: query: insert overwrite table nzhang_ctas6 select key, value from src limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@nzhang_ctas6
POSTHOOK: Lineage: nzhang_ctas6.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: nzhang_ctas6.to SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: create table nzhang_ctas7 as select key, `to` from nzhang_ctas6
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@nzhang_ctas6
POSTHOOK: query: create table nzhang_ctas7 as select key, `to` from nzhang_ctas6
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@nzhang_ctas6
POSTHOOK: Output: default@nzhang_ctas7
POSTHOOK: Lineage: nzhang_ctas6.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: nzhang_ctas6.to SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
